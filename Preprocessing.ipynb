{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Para trabajar con NLP tenemos que preprocesar el texto de diferentes formas, según el problema que queramos solucionar. En este notebook vamos a ver las diferentes formas que tenemos de modificar el texto para facilitar el trabajo a los algoritmos de NLP.\n",
    "\n",
    "**Importante:** según el problema que queramos resolver tendremos que realizar unas u otras operaciones sobre el texto. Por ejemplo, para generación de lenguaje natural, no deberíamos _romper_ las palabras. En cambio, si queremos clasificar texto, no nos interesa que _gato_, _gata_, _gatos_, _gatas_ lo tome como palabras diferentes."
   ]
  },
  {
   "source": [
    "## Stopwords\n",
    "\n",
    "Las _stopwords_ son palabras que no tienen significado por sí mismas y que, normalmente, queremos eliminar de nuestros textos. Para cada idioma, tenemos diferentes _stopwords_. Antes de preprocesar el texto, vamos a descargar estas _stopwords_."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/gallardo/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Descargar las Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado\n",
    "\n",
    "Hemos creado una clase para preprocesar el texto. Vamos a ver el funcionamiento de esta clase. Lo primero que tenemos que hacer es instanciar la clase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import Preprocessor\n",
    "preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando preprocesamos el texto, vamos a trabajar con tokens. Lo primero que vamos a hacer es cargar el texto y ver los tokens que se han geneado.\n",
    "\n",
    "Nosotros vamos a tokenizar con `nltk`.\n",
    "\n",
    "```python\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "def set_text(self, text):\n",
    "    self.__tokens = wordpunct_tokenize(text if text else '')\n",
    "    return self\n",
    "\n",
    "def get_tokens(self):\n",
    "    return self.__tokens\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Seven',\n 'Dwarves',\n 'gets',\n '+',\n '1',\n '/+',\n '1',\n 'for',\n 'each',\n 'other',\n 'creature',\n 'named',\n 'Seven',\n 'Dwarves',\n 'you',\n 'control',\n '.',\n 'A',\n 'deck',\n 'can',\n 'have',\n 'up',\n 'to',\n 'seven',\n 'cards',\n 'named',\n 'Seven',\n 'Dwarves',\n '.']"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "sample = \"Seven Dwarves gets +1/+1 for each other creature named Seven Dwarves you control. A deck can have up to seven cards named Seven Dwarves.\"\n",
    "preprocessor.set_text(sample)\n",
    "preprocessor.get_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizar el texto\n",
    "Antes de continuar vamos a estandarizar el texto. Vamos a dejar todo el texto en minúsculas y a eliminar los números y signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'seven dwarves gets for each other creature named seven dwarves you control a deck can have up to seven cards named seven dwarves'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "preprocessor.standardize()\n",
    "preprocessor.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar _stopwords_\n",
    "Como hemos visto antes, las _stopwords_ son palabras que no nos van a aportar nada (según el problema que vayamos a resolver), así que las podemos eliminar.\n",
    "\n",
    "Vamos a ver qué palabras son las _stopwords_ para el español y para el inglés. A continuación vamos a llamar al método `remove_stop_words` para eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Stopword in spanish:  313\n['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']\nStopword in english:  179\n['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(\"Stopword in spanish: \", len(stopwords.words('spanish')))\n",
    "print(stopwords.words('spanish')[:10])\n",
    "print(\"Stopword in english: \", len(stopwords.words('english')))\n",
    "print(stopwords.words('english')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'seven dwarves gets creature named seven dwarves control deck seven cards named seven dwarves'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "preprocessor.remove_stop_words()\n",
    "preprocessor.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchos problemas de NLP (como la clasificación que vamos a ver) no nos intenresa que contemple una palabra con sus diferentes variantes de género, número o familia de palabra. Por tanto, tenemos dos opciones para unificar todas esas palabras: Stemming o Lemmatization.\n",
    "\n",
    "### Stemming\n",
    "Con el `Stemming` vamos a cortar la palabra para quedarnos con la parte común.\n",
    "\n",
    "_Para **gatos, gato, gata, gatas** sería **gat**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['gat', 'gat', 'gat', 'gat']"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "stem = \"gato gatos gata gatas\"\n",
    "stem_preprocessor = Preprocessor(language='spanish', language_code='es')\n",
    "stem_preprocessor.set_text(stem).stemming()\n",
    "stem_preprocessor.get_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Con la `Lemmatization` vamos a quedarnos con el _lemma_ (palabra canónica, palabra del diccionario).\n",
    "\n",
    "_Para **gatos, gato, gata, gatas**, sería **gato**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['gato', 'gato', 'gato', 'gato']"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "lemma = \"gato gatos gata gatas\"\n",
    "lemma_preprocessor = Preprocessor(language='spanish', language_code='es')\n",
    "lemma_preprocessor.set_text(lemma).lemmatization()\n",
    "lemma_preprocessor.get_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro ejemplo, nos vamos a quedar con la `Lemmatization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'seven dwarf get creature name seven dwarf control deck seven card name seven dwarf'"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "preprocessor.lemmatization()\n",
    "preprocessor.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Ahora podemos ver la diferencia entre el texto de entrada y el texto preprocesado. Adelante, puedes probar cosas :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sample: Los Siete enanitos obtienen +1/+1 por cada otra criatura llamada Siete enanitos que controlas. Un mazo puede tener más de cuatro cartas, hasta siete llamadas Siete enanitos.\n\nStandarize: los siete enanitos obtienen por cada otra criatura llamada siete enanitos que controlas un mazo puede tener más de cuatro cartas hasta siete llamadas siete enanitos\n\nRemove stopwords: siete enanitos obtienen cada criatura llamada siete enanitos controlas mazo puede tener cuatro cartas siete llamadas siete enanitos\n\nRemove accents: siete enanitos obtienen cada criatura llamada siete enanitos controlas mazo puede tener cuatro cartas siete llamadas siete enanitos\n\nStemming: siet enanit obtien cad criatur llam siet enanit control maz pued ten cuatr cart siet llam siet enanit\n\nLemmatization: siete enanitos obtener cada criatura llamar siete enanitos controlar mazar poder tener cuatro carta siete llamar siete enanitos\n\n"
    }
   ],
   "source": [
    "from utils.preprocessing import Preprocessor\n",
    "\n",
    "sample = \"Los Siete enanitos obtienen +1/+1 por cada otra criatura llamada Siete enanitos que controlas. Un mazo puede tener más de cuatro cartas, hasta siete llamadas Siete enanitos.\"\n",
    "\n",
    "preprocessor = Preprocessor(language=\"spanish\", language_code=\"es\")\n",
    "\n",
    "output = preprocessor.set_text(sample).standardize().remove_stop_words().get_text()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Sample: {sample}\\n\")\n",
    "print(f\"Standarize: {preprocessor.set_text(sample).standardize()}\\n\")\n",
    "print(f\"Remove stopwords: {preprocessor.set_text(sample).standardize().remove_stop_words()}\\n\")\n",
    "print(f\"Remove accents: {preprocessor.set_text(sample).standardize().remove_stop_words().remove_accents()}\\n\")\n",
    "print(f\"Stemming: {preprocessor.set_text(sample).standardize().remove_stop_words().remove_accents().stemming()}\\n\")\n",
    "print(f\"Lemmatization: {preprocessor.set_text(sample).standardize().remove_stop_words().remove_accents().lemmatization()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('mtg-class': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600181167575"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}